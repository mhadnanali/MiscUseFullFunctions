{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1d8265",
   "metadata": {},
   "outputs": [],
   "source": [
    " # import the module\n",
    "import tweepy\n",
    "import csv\n",
    "import time\n",
    "import tweepy\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('drive/gdrive/MyDrive')\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "\n",
    "#Read file and get only usernames\n",
    "path=\"gdrive/MyDrive/AirPorts/\"\n",
    "usernames=pd.read_excel(path+'AirPorts.xlsx')\n",
    "names=usernames['uname'].values.tolist()\n",
    "names = [str(x) for x in names]\n",
    "newlist = [x for x in names if x != 'nan']\n",
    "unames=[]\n",
    "for username in newlist:\n",
    "    unames.append(username.replace(\"https://twitter.com/\", \"\"))\n",
    "\n",
    "count=0;\n",
    "#Authentication\n",
    "consumer_key        =\"\"\n",
    "consumer_secret     =\"\"\n",
    "access_token        =\"\"\n",
    "access_token_secret =\"\"\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth,wait_on_rate_limit=True )\n",
    "allusersdf = pd.DataFrame(columns=['user','tweets'])\n",
    "# calling the api\n",
    "#api = tweepy.API(auth)\n",
    "\n",
    "api = tweepy.API(auth, parser=tweepy.parsers.JSONParser(),wait_on_rate_limit=True)\n",
    "for user in unames:\n",
    "  # screen name of the account to be fetched\n",
    "  print(user)  \n",
    "  max_pages=0\n",
    "  result_limit=0\n",
    "  count=0\n",
    "  usertweetcounter=0\n",
    "  filname= user+ \" Tweet\"\n",
    "  \n",
    "  jsonFile = open(path+filname+'.json', \"a+\",encoding='utf-8')\n",
    "  page=1\n",
    "  max_pages=160\n",
    "  result_limit=20\n",
    "  last_tweet_id=False \n",
    "  while page <= max_pages:\n",
    "              if last_tweet_id: \n",
    "                  tweet   =   api.user_timeline(screen_name=user,\n",
    "                                                      count=result_limit,\n",
    "                                                      max_id=last_tweet_id - 1,\n",
    "                                                      tweet_mode = 'extended',\n",
    "                                                      include_retweets=True\n",
    "                                                      )        \n",
    "              else:\n",
    "                  tweet   =   api.user_timeline(screen_name=user,\n",
    "                                                          count=result_limit,\n",
    "                                                          tweet_mode = 'extended',\n",
    "                                                          include_retweets=True)\n",
    "              if len(tweet)!=0:                 \n",
    "                json_str = json.dumps(tweet, ensure_ascii=False, indent=4)\n",
    "                #print(json_str)\n",
    "                jsonFile.write(json_str)\n",
    "                usertweetcounter=usertweetcounter+len(tweet)\n",
    "                print(str(usertweetcounter) + \" number of statuses have been fetched for .\"+ user)\n",
    "\n",
    "                for item in tweet:\n",
    "                  #print(type(item))\n",
    "                  #print(item)\n",
    "                  last_tweet_id=item['id']\n",
    "              else: \n",
    "                print(\"Empty response...\")\n",
    "\n",
    "              #last_tweet_id = item.id\n",
    "              page += 1\n",
    "              print('Page ',page,' Last Tweet :',last_tweet_id)\n",
    "  usertweetcounter=usertweetcounter+len(tweet)\n",
    "  print(str(usertweetcounter) + \" Grand Total for.\"+ user)\n",
    "  values_to_add = {'user': user,'tweets':usertweetcounter} #'user','tweets'\n",
    "  row_to_add = pd.Series(values_to_add)\n",
    "  allusersdf = allusersdf.append(row_to_add, ignore_index=True)\n",
    "  print(allusersdf)\n",
    "  allusersdf.to_csv(path+\" The AirPorts Tweet Stats.csv\")\n",
    "allusersdf.to_csv(path+\" The AirPorts Tweet Stats.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
